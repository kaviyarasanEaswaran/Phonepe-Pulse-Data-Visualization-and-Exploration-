{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9061a145-b2c5-4190-a1a2-49c197a43fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aab8cd11-204b-4d86-bfb6-315fc580d9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn=psycopg2.connect(host=\"localhost\",\n",
    "                      user=\"postgres\",\n",
    "                      password=\"Kavidhina@5566\",\n",
    "                      port=5432,\n",
    "                      database=\"phonepe_pulse\")\n",
    "cursor=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2a1a1a2f-27ca-4945-8f89-081da9d9e5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data=migrate_alldata_tosql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "613122dc-faeb-4bbc-bd6b-43915ef95280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_alldata_tosql():\n",
    "    df1=complete_aggregated_datas()\n",
    "    create_sql_table_aggregated()\n",
    "    migrate_sql_table_aggregated()\n",
    "    df2=complete_map_datas()\n",
    "    create_sql_table_map()\n",
    "    migrate_sql_table_map()\n",
    "    df3=complete_top_datas()\n",
    "    create_sql_table_top()\n",
    "    migrate_sql_table_top()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c381976-e5e1-4659-9494-6086258e0d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_aggregated_datas():\n",
    "    #aggregated\n",
    "    # 1.aggregated trasaction\n",
    "    aggre_trans_path = \"D:/Data Science/Git_Clone/Data/pulse/data/aggregated/transaction/country/india/\"\n",
    "    aggre_trans_list = os.listdir(aggre_trans_path) \n",
    "\n",
    "    #1.1 year wise aggregated trasaction\n",
    "    aggre_trans_year_wise = dict (categories=[],year=[],quarter=[],count=[],amount=[])\n",
    "    for year in range(len(aggre_trans_list)-1):\n",
    "        json_path = aggre_trans_path+aggre_trans_list[year]+\"/\"\n",
    "        json_file_list = os.listdir(json_path)\n",
    "        quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            with open(f\"{json_path + json_file_list[json_file]}\") as df:\n",
    "                file = json.load(df)\n",
    "            aggre_trans_year_wise['categories'].append(file['data']['transactionData'][0]['name'])\n",
    "            aggre_trans_year_wise['year'].append(aggre_trans_list[year])\n",
    "            aggre_trans_year_wise['quarter'].append(quarter[json_file])\n",
    "            aggre_trans_year_wise['count'].append(file['data']['transactionData'][0]['paymentInstruments'][0]['count'])\n",
    "            aggre_trans_year_wise['amount'].append(file['data']['transactionData'][0]['paymentInstruments'][0]['amount'])\n",
    "\n",
    "    #1.2 state wise aggregated trasaction\n",
    "    aggre_trans_state_wise = dict (categories=[],year=[],quarter=[],state=[],count=[],amount=[]) \n",
    "    state_path = aggre_trans_path+\"state\"+\"/\"\n",
    "    state_list = os.listdir(state_path)\n",
    "    for state in range(len(state_list)):\n",
    "        year_path = state_path+state_list[state]+\"/\"\n",
    "        years_list = os.listdir(year_path)\n",
    "        for year in range(len(years_list)):\n",
    "            json_path = year_path+\"/\"+years_list[year]\n",
    "            json_file_list = os.listdir(json_path)\n",
    "            for json_file in range (len(json_file_list)):\n",
    "                df = open(f\"{json_path+'/'+json_file_list[json_file]}\")\n",
    "                file = json.load(df)            \n",
    "                quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]  \n",
    "                aggre_trans_state_wise['categories'].append(file['data']['transactionData'][0]['name'])\n",
    "                aggre_trans_state_wise['year'].append(years_list[year])\n",
    "                aggre_trans_state_wise['state'].append(state_list[state])\n",
    "                aggre_trans_state_wise['quarter'].append(quarter[json_file])\n",
    "                aggre_trans_state_wise['count'].append(file['data']['transactionData'][0]['paymentInstruments'][0]['count'])\n",
    "                aggre_trans_state_wise['amount'].append(file['data']['transactionData'][0]['paymentInstruments'][0]['amount'])\n",
    "            \n",
    "    #2.aggregated user\n",
    "    aggre_user_path = \"D:/Data Science/Git_Clone/Data/pulse/data/aggregated/user/country/india/\"\n",
    "    aggre_user_list = os.listdir(aggre_user_path) \n",
    "    #2.1 year wise aggregated user\n",
    "    aggre_user_year_wise = dict(registered_user=[],app_open=[],year=[],quarter=[],brand=[],count=[],percentage=[])\n",
    "    for year in range(len(aggre_user_list)-1):\n",
    "        json_path = aggre_user_path+aggre_user_list[year]+\"/\"\n",
    "        json_file_list = os.listdir(json_path)\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "            file = json.load(df)\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            usersByDevice_list = file['data']['usersByDevice']\n",
    "            if usersByDevice_list is not None:\n",
    "                for userBydevice in range (len(usersByDevice_list)):\n",
    "                    aggre_user_year_wise['registered_user'].append(file['data']['aggregated']['registeredUsers'])\n",
    "                    aggre_user_year_wise['app_open'].append(file['data']['aggregated']['appOpens'])\n",
    "                    aggre_user_year_wise['year'].append(aggre_user_list[year])\n",
    "                    aggre_user_year_wise['quarter'].append(quarter[json_file])            \n",
    "                    aggre_user_year_wise['brand'].append(usersByDevice_list[userBydevice]['brand'])\n",
    "                    aggre_user_year_wise['count'].append(usersByDevice_list[userBydevice]['count'])\n",
    "                    aggre_user_year_wise['percentage'].append(usersByDevice_list[userBydevice]['percentage'])\n",
    "            else:\n",
    "                    aggre_user_year_wise['registered_user'].append(file['data']['aggregated']['registeredUsers'])\n",
    "                    aggre_user_year_wise['app_open'].append(file['data']['aggregated']['appOpens'])\n",
    "                    aggre_user_year_wise['year'].append(aggre_user_list[year])\n",
    "                    aggre_user_year_wise['quarter'].append(quarter[json_file])            \n",
    "                    aggre_user_year_wise['brand'].append(None)\n",
    "                    aggre_user_year_wise['count'].append(0)\n",
    "                    aggre_user_year_wise['percentage'].append(None)\n",
    "            \n",
    "    #2.2 state wise aggregated user    \n",
    "    aggre_user_state_wise = dict(registered_user=[],app_open=[],year=[],quarter=[],state=[],brand=[],count=[],percentage=[])\n",
    "    state_path=aggre_user_path+\"state\"+\"/\"\n",
    "    state_list=os.listdir(state_path) \n",
    "    for state in state_list:\n",
    "        year_path = state_path+state+\"/\"\n",
    "        year_list=os.listdir(year_path)\n",
    "        for year in range(len(year_list)):\n",
    "            json_path=year_path+year_list[year]+\"/\"\n",
    "            json_list=os.listdir(json_path)\n",
    "            for json_file in range(len(json_list)):\n",
    "                df=open(f\"{json_path+json_list[json_file]}\")\n",
    "                file=json.load(df)\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            usersByDevice_list = file['data']['usersByDevice']\n",
    "            if usersByDevice_list is not None:\n",
    "                for userBydevice in range (len(usersByDevice_list)):\n",
    "                    aggre_user_state_wise['registered_user'].append(file['data']['aggregated']['registeredUsers'])\n",
    "                    aggre_user_state_wise['app_open'].append(file['data']['aggregated']['appOpens'])\n",
    "                    aggre_user_state_wise['year'].append(year_list[year])\n",
    "                    aggre_user_state_wise['quarter'].append(quarter[json_file])\n",
    "                    aggre_user_state_wise['state'].append(state)\n",
    "                    aggre_user_state_wise['brand'].append(usersByDevice_list[userBydevice]['brand'])\n",
    "                    aggre_user_state_wise['count'].append(usersByDevice_list[userBydevice]['count'])\n",
    "                    aggre_user_state_wise['percentage'].append(usersByDevice_list[userBydevice]['percentage'])\n",
    "            else:\n",
    "                    aggre_user_state_wise['registered_user'].append(file['data']['aggregated']['registeredUsers'])\n",
    "                    aggre_user_state_wise['app_open'].append(file['data']['aggregated']['appOpens'])\n",
    "                    aggre_user_state_wise['year'].append(aggre_user_list[year])\n",
    "                    aggre_user_state_wise['quarter'].append(quarter[json_file])\n",
    "                    aggre_user_state_wise['state'].append(state)\n",
    "                    aggre_user_state_wise['brand'].append(None)\n",
    "                    aggre_user_state_wise['count'].append(0)\n",
    "                    aggre_user_state_wise['percentage'].append(None)\n",
    "    df_aggre_trans_year_wise = pd.DataFrame(aggre_trans_year_wise)\n",
    "    df_aggre_trans_state_wise = pd.DataFrame(aggre_trans_state_wise)\n",
    "    df_aggre_user_year_wise = pd.DataFrame(aggre_user_year_wise)\n",
    "    df_aggre_user_state_wise = pd.DataFrame(aggre_user_state_wise)\n",
    "    df1=[df_aggre_trans_year_wise,df_aggre_trans_state_wise,df_aggre_user_year_wise,df_aggre_user_state_wise]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b3d8c56-3882-4bcf-9ce8-c88f4d453286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_map_datas():\n",
    "\n",
    "    #map\n",
    "    #1.map transaction\n",
    "    map_transaction_path = \"D:/Data Science/Git_Clone/Data/pulse/data/map/transaction/hover/country/india/\"\n",
    "    map_transaction_list=os.listdir(map_transaction_path)\n",
    "\n",
    "    #1.1 year wise map transaction\n",
    "    map_transaction_year_wise = dict(categories=[],year=[],quarter=[],count=[],amount=[])\n",
    "    for year in range(len(map_transaction_list)-1):\n",
    "        json_path = map_transaction_path+map_transaction_list[year]+\"/\"\n",
    "        json_file_list = os.listdir(json_path)\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "            file = json.load(df)\n",
    "            hoverDataList = file['data']['hoverDataList']\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            for values in hoverDataList:\n",
    "                map_transaction_year_wise['categories'].append(values['name'])\n",
    "                map_transaction_year_wise['year'].append(map_transaction_list[year])\n",
    "                map_transaction_year_wise['quarter'].append(quarter[json_file])\n",
    "                map_transaction_year_wise['count'].append(values['metric'][0]['count'])\n",
    "                map_transaction_year_wise['amount'].append(values['metric'][0]['amount'])\n",
    "            \n",
    "    #1.2 state wise map transaction\n",
    "    map_transaction_state_wise = dict(district=[],year=[],quarter=[],state=[],count=[],amount=[])\n",
    "    state_path = map_transaction_path+\"state\"+\"/\"\n",
    "    state_list = os.listdir(state_path)\n",
    "    for state in state_list:\n",
    "        year_path = state_path+state+\"/\"\n",
    "        year_list = os.listdir(year_path)\n",
    "        for year in year_list:\n",
    "            json_path = year_path+year+\"/\"\n",
    "            json_file_list = os.listdir(json_path)\n",
    "            for json_file in range(len(json_file_list)):\n",
    "                df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "                file = json.load(df)\n",
    "            hoverDataList = file['data']['hoverDataList']\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            for values in hoverDataList:\n",
    "                map_transaction_state_wise['district'].append(values['name'])\n",
    "                map_transaction_state_wise['year'].append(year)\n",
    "                map_transaction_state_wise['quarter'].append(quarter[json_file])\n",
    "                map_transaction_state_wise['state'].append(state)\n",
    "                map_transaction_state_wise['count'].append(values['metric'][0]['count'])\n",
    "                map_transaction_state_wise['amount'].append(values['metric'][0]['amount'])\n",
    "              \n",
    "    #2.map user\n",
    "    map_user_path = \"D:/Data Science/Git_Clone/Data/pulse/data/map/user/hover/country/india/\"\n",
    "    map_user_list=os.listdir(map_user_path)\n",
    "\n",
    "    #2.1 year wise map user\n",
    "    map_user_year_wise = dict(registered_users=[],app_open=[],state=[],year=[],quarter=[])\n",
    "    for year in range(len(map_transaction_list)-1):\n",
    "        json_path = map_user_path+map_user_list[year]+\"/\"\n",
    "        json_file_list = os.listdir(json_path)\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "            file = json.load(df)\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            state_list = ['puducherry','tamil nadu','uttar pradesh','madhya pradesh','andhra pradesh','tripura',\n",
    "                     'lakshadweep','manipur','maharashtra','dadra & nagar haveli & daman & diu','meghalaya',\n",
    "                     'andaman & nicobar islands','haryana','rajasthan','ladakh','punjab','assam','jharkhand',\n",
    "                     'odisha','bihar','kerala','karnataka','chandigarh','telangana','himachal pradesh',\n",
    "                     'west bengal','gujarat','sikkim','nagaland','mizoram','chhattisgarh','jammu & kashmir','goa',\n",
    "                     'arunachal pradesh','delhi','uttarakhand']\n",
    "            for state in state_list:\n",
    "                map_user_year_wise['registered_users'].append(file['data']['hoverData'][state]['registeredUsers'])\n",
    "                map_user_year_wise['app_open'].append(file['data']['hoverData'][state]['appOpens'])\n",
    "                map_user_year_wise['year'].append(map_user_list[year])\n",
    "                map_user_year_wise['state'].append(state)\n",
    "                map_user_year_wise['quarter'].append(quarter[json_file])\n",
    "\n",
    "    #2.2 state wise map user\n",
    "    map_user_state_wise = dict(registered_users=[],app_open=[],state=[],district=[],year=[],quarter=[])\n",
    "    state_path = map_user_path+\"state\"+\"/\"\n",
    "    state_list = os.listdir(state_path)\n",
    "    for state in state_list:\n",
    "        year_path = state_path+state+\"/\"\n",
    "        year_list = os.listdir(year_path)\n",
    "        for year in year_list:\n",
    "            json_path = year_path+year+\"/\"\n",
    "            json_file_list = os.listdir(json_path)\n",
    "            for json_file in range(len(json_file_list)):\n",
    "                df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "                file=json.load(df)\n",
    "                data=list(file['data']['hoverData'].keys())\n",
    "                quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "                for values in data:\n",
    "                    map_user_state_wise['state'].append(state)\n",
    "                    map_user_state_wise['district'].append(values)\n",
    "                    map_user_state_wise['year'].append(year)\n",
    "                    map_user_state_wise['quarter'].append(quarter[json_file])\n",
    "                    map_user_state_wise['registered_users'].append(file['data']['hoverData'][values]['registeredUsers'])\n",
    "                    map_user_state_wise['app_open'].append(file['data']['hoverData'][values]['appOpens'])\n",
    "    df_map_transaction_year_wise=pd.DataFrame(map_transaction_year_wise)\n",
    "    df_map_transaction_state_wise=pd.DataFrame(map_transaction_state_wise)\n",
    "    df_map_user_year_wise=pd.DataFrame(map_user_year_wise)\n",
    "    df_map_user_state_wise=pd.DataFrame(map_user_state_wise)\n",
    "    df2=[df_map_transaction_year_wise,df_map_transaction_state_wise,df_map_user_year_wise,df_map_user_state_wise]\n",
    "    return df2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "05e08b2e-521e-416c-99be-804de3548b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_top_datas():\n",
    "    #top\n",
    "    #1.top transaction\n",
    "    top_transaction_path = \"D:/Data Science/Git_Clone/Data/pulse/data/top/transaction/country/india/\"\n",
    "    top_transaction_list=os.listdir(top_transaction_path)\n",
    "\n",
    "    #1.1 year wise top transaction\n",
    "    top_transaction_year_wise=dict(state=[],state_count=[],state_amount=[],year=[],quarter=[],\n",
    "                                   pincode=[],pincode_amount=[],pincode_count=[],\n",
    "                                   district=[],district_amount=[],district_count=[])\n",
    "    for year in range(len(top_transaction_list)-1):\n",
    "        json_path = top_transaction_path+top_transaction_list[year]+\"/\"\n",
    "        json_file_list =os.listdir(json_path)\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "            file=json.load(df)\n",
    "            values1 = file['data']['states']\n",
    "            values2 = file['data']['districts']\n",
    "            values3 = file['data']['pincodes']\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            if len(values1) == len(values2) == len(values3) :\n",
    "                for values in range(len(values1)):\n",
    "                    top_transaction_year_wise['state'].append(values1[values]['entityName'])\n",
    "                    top_transaction_year_wise['state_count'].append(values1[values]['metric']['count'])\n",
    "                    top_transaction_year_wise['state_amount'].append(values1[values]['metric']['amount'])\n",
    "                    top_transaction_year_wise['year'].append(top_transaction_list[year])\n",
    "                    top_transaction_year_wise['quarter'].append(quarter[json_file])\n",
    "                    top_transaction_year_wise['district'].append(values2[values]['entityName'])\n",
    "                    top_transaction_year_wise['district_count'].append(values2[values]['metric']['count'])\n",
    "                    top_transaction_year_wise['district_amount'].append(values2[values]['metric']['amount'])\n",
    "                    top_transaction_year_wise['pincode'].append(values3[values]['entityName'])\n",
    "                    top_transaction_year_wise['pincode_count'].append(values3[values]['metric']['count'])\n",
    "                    top_transaction_year_wise['pincode_amount'].append(values3[values]['metric']['amount'])\n",
    "                    \n",
    "    #1.2 state wise top transaction\n",
    "    state_path=top_transaction_path+\"state\"+\"/\"\n",
    "    state_list=os.listdir(state_path) \n",
    "    top_transaction_state_wise=dict(state=[],district=[],district_count=[],district_amount=[],\n",
    "                                    year=[],quarter=[],pincode=[],pincode_count=[],pincode_amount=[])\n",
    "    for state in state_list:\n",
    "        year_path=state_path+state+\"/\"\n",
    "        year_list=os.listdir(year_path)\n",
    "        for year in year_list:\n",
    "            json_path=year_path+year+\"/\"\n",
    "            json_file_list=os.listdir(json_path)\n",
    "            for json_file in range(len(json_file_list)):\n",
    "                df=open(f\"{json_path+json_file_list[json_file]}\")\n",
    "                file=json.load(df)\n",
    "                districts=file['data']['districts']\n",
    "                quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "                values1 = file['data']['districts']\n",
    "                values2 = file['data']['pincodes']\n",
    "                for values in range(len(values2)):\n",
    "                    try:\n",
    "                        top_transaction_state_wise['district'].append(values1[values]['entityName'])\n",
    "                        top_transaction_state_wise['pincode'].append(values2[values]['entityName'])\n",
    "                        top_transaction_state_wise['state'].append(state)\n",
    "                        top_transaction_state_wise['pincode_count'].append(values2[values]['metric']['count'])\n",
    "                        top_transaction_state_wise['pincode_amount'].append(values2[values]['metric']['count'])\n",
    "                        top_transaction_state_wise['district_count'].append(values1[values]['metric']['count'])\n",
    "                        top_transaction_state_wise['district_amount'].append(values1[values]['metric']['amount'])\n",
    "                        top_transaction_state_wise['year'].append(year)\n",
    "                        top_transaction_state_wise['quarter'].append(quarter[json_file])\n",
    "                        \n",
    "                    except IndexError:\n",
    "                        top_transaction_state_wise['district'].append(None)\n",
    "                        top_transaction_state_wise['pincode'].append(values2[values]['entityName'])\n",
    "                        top_transaction_state_wise['state'].append(state)\n",
    "                        top_transaction_state_wise['pincode_count'].append(values2[values]['metric']['count'])\n",
    "                        top_transaction_state_wise['pincode_amount'].append(values2[values]['metric']['count'])\n",
    "                        top_transaction_state_wise['district_count'].append(0)\n",
    "                        top_transaction_state_wise['district_amount'].append(0)\n",
    "                        top_transaction_state_wise['year'].append(year)\n",
    "                        top_transaction_state_wise['quarter'].append(quarter[json_file])\n",
    "    #2.top user\n",
    "    top_user_path = \"D:/Data Science/Git_Clone/Data/pulse/data/top/user/country/india/\"\n",
    "    top_user_list = os.listdir(top_user_path)\n",
    "\n",
    "    #2.1 year wise top user\n",
    "    top_user_path = \"D:/Data Science/Git_Clone/Data/pulse/data/top/user/country/india/\"\n",
    "    top_user_list = os.listdir(top_user_path)\n",
    "    top_user_year_wise=dict(state=[],state_registered_users=[],year=[],quarter=[],\n",
    "                            district=[],district_registered_users=[],\n",
    "                            pincode=[],pincode_registered_users=[])\n",
    "    for year in range(len(top_user_list)-1):\n",
    "        json_path = top_user_path+top_user_list[year]+\"/\"\n",
    "        json_file_list =os.listdir(json_path)\n",
    "        for json_file in range(len(json_file_list)):\n",
    "            df=open(f\"{json_path+json_file_list[json_file]}\")\n",
    "            file=json.load(df)\n",
    "            states=file['data']['states']\n",
    "            quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "            values1 = file['data']['states']\n",
    "            values2 = file['data']['districts']\n",
    "            values3 = file['data']['pincodes']\n",
    "            for values in range(len(values1)):\n",
    "                top_user_year_wise['state'].append(values1[values]['name'])\n",
    "                top_user_year_wise['state_registered_users'].append(values1[values]['registeredUsers'])\n",
    "                top_user_year_wise['year'].append(top_user_list[year])\n",
    "                top_user_year_wise['quarter'].append(quarter[json_file])\n",
    "                top_user_year_wise['district'].append(values2[values]['name'])\n",
    "                top_user_year_wise['district_registered_users'].append(values2[values]['registeredUsers'])\n",
    "                top_user_year_wise['pincode'].append(values3[values]['name'])\n",
    "                top_user_year_wise['pincode_registered_users'].append(values3[values]['registeredUsers'])\n",
    "                    \n",
    "    #2.2 state wise top user  \n",
    "    state_path = top_user_path+\"state\"+\"/\"\n",
    "    state_list = os.listdir(state_path)\n",
    "    top_user_state_wise = dict(state=[],district=[],district_registered_users=[],pincode=[],pincode_registered_users=[],year=[],quarter=[])\n",
    "    for state in state_list:\n",
    "        year_path = state_path+state+\"/\"\n",
    "        year_list = os.listdir(year_path)\n",
    "        for year in year_list:\n",
    "            json_path = year_path+year+\"/\"\n",
    "            json_file_list = os.listdir(json_path)\n",
    "            for json_file in range(len(json_file_list)):\n",
    "                df = open(f\"{json_path+json_file_list[json_file]}\")\n",
    "                file = json.load(df)\n",
    "                #pprint.pprint(file)\n",
    "                ditrict = file['data']['districts']\n",
    "                quarter = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n",
    "                values1 = file['data']['districts']\n",
    "                values2 = file['data']['pincodes']\n",
    "                for values in range(len(values2)):\n",
    "                    try:\n",
    "                        top_user_state_wise['district'].append(values1[values]['name'])\n",
    "                        top_user_state_wise['pincode'].append(values2[values]['name'])\n",
    "                        top_user_state_wise['state'].append(state)\n",
    "                        top_user_state_wise['district_registered_users'].append(values1[values]['registeredUsers'])\n",
    "                        top_user_state_wise['pincode_registered_users'].append(values2[values]['registeredUsers'])\n",
    "                        top_user_state_wise['year'].append(year)\n",
    "                        top_user_state_wise['quarter'].append(quarter[json_file])\n",
    "                    except IndexError:\n",
    "                        top_user_state_wise['state'].append(state)\n",
    "                        top_user_state_wise['district'].append(None)\n",
    "                        top_user_state_wise['pincode'].append(values2[values]['name'])\n",
    "                        top_user_state_wise['district_registered_users'].append(0)\n",
    "                        top_user_state_wise['pincode_registered_users'].append(values2[values]['registeredUsers'])\n",
    "                        top_user_state_wise['year'].append(year)\n",
    "                        top_user_state_wise['quarter'].append(quarter[json_file])\n",
    " \n",
    "    df_top_transaction_year_wise=pd.DataFrame(top_transaction_year_wise)\n",
    "    df_top_transaction_state_wise=pd.DataFrame(top_transaction_state_wise)\n",
    "    df_top_user_year_wise=pd.DataFrame(top_user_year_wise)\n",
    "    df_top_user_state_wise=pd.DataFrame(top_user_state_wise)\n",
    "    df3=[df_top_transaction_year_wise,df_top_transaction_state_wise,df_top_user_year_wise,df_top_user_state_wise]\n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c32f1b7-5a47-44c1-a612-1ba3975dedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_table_aggregated():\n",
    "    query=\"create table if not exists aggre_trans_year_wise(categories varchar (250),year int,quarter varchar (10),count BIGINT,amount float)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists aggre_trans_state_wise(categories varchar (250),year int,quarter varchar (10),state varchar (50),count BIGINT,amount float)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists aggre_user_year_wise(registered_user BIGINT,app_open BIGINT,year int,quarter varchar (10),brand varchar (50),count BIGINT,percentage varchar (50)) \"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists aggre_user_state_wise(registered_user BIGINT,app_open BIGINT,year int,quarter varchar (10),state varchar (50),brand varchar (50),count BIGINT,percentage varchar (50)) \"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfadf634-4d2f-4aba-b34c-3ec9209e2b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sql_table_map():\n",
    "    query=\"create table if not exists map_trans_year_wise(categories varchar (250),year int,quarter varchar (10),count BIGINT,amount float)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists map_trans_state_wise(district varchar (50),year int,quarter varchar (10),state varchar (50),count BIGINT,amount float)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists map_user_year_wise(registered_user BIGINT,app_open BIGINT,state varchar(50),year int,quarter varchar (10))\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists map_user_state_wise(registered_user BIGINT,app_open BIGINT,state varchar (50),district varchar (50),year int,quarter varchar (10))\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4be0ad87-1039-4f27-ad68-e102a3f199d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sql_table_top():\n",
    "    query=\"create table if not exists top_trans_year_wise(state varchar (50),state_count bigint,state_amount float,year int,quarter varchar(10),pincode int,pincode_amount float,pincode_count bigint,district varchar(50),district_amount float,district_count bigint)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists top_trans_state_wise(state varchar (50),district varchar (50),district_count BIGINT,district_amount float,year int,quarter varchar (10),pincode int,pincode_count bigint,pincode_amount float)\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists top_user_year_wise(state varchar(50),state_registered_user BIGINT,year int,quarter varchar (10),district varchar (50),district_registered_users BIGINT,pincode int,pincode_registered_users bigint) \"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    query=\"create table if not exists top_user_state_wise(state varchar (50),district varchar (50),district_registered_user BIGINT,pincode int,pincode_registered_users bigint,year int,quarter varchar (10))\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ecd76d3-c829-4982-a6b1-dd24b6a036fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_sql_table_aggregated():\n",
    "    values=df1[0].values.tolist()\n",
    "    query=\"insert into aggre_trans_year_wise values (%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df1[1].values.tolist()\n",
    "    query=\"insert into aggre_trans_state_wise values (%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df1[2].values.tolist()\n",
    "    query=\"insert into aggre_user_year_wise values (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df1[3].values.tolist()\n",
    "    query=\"insert into aggre_user_state_wise values (%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5cd92930-600d-4a74-927d-d60b7b1c4f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_sql_table_map():\n",
    "    values=df2[0].values.tolist()\n",
    "    query=\"insert into map_trans_year_wise values (%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df2[1].values.tolist()\n",
    "    query=\"insert into map_trans_state_wise values (%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df2[2].values.tolist()\n",
    "    query=\"insert into map_user_year_wise values (%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df2[3].values.tolist()\n",
    "    query=\"insert into map_user_state_wise values (%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da8c392a-3615-40b6-993d-c414107ec0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_sql_table_top():\n",
    "    values=df3[0].values.tolist()\n",
    "    query=\"insert into top_trans_year_wise values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df3[1].values.tolist()\n",
    "    query=\"insert into top_trans_state_wise values (%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df3[2].values.tolist()\n",
    "    query=\"insert into top_user_year_wise values (%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    values=df3[3].values.tolist()\n",
    "    query=\"insert into top_user_state_wise values (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    cursor.executemany(query,values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c537e-8172-4e90-91f4-4de422abed50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
